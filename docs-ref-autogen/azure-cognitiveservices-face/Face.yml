### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-face.Face
    name: Face
    fullName: Face
    children:
      - azure-cognitiveservices-face.Face.detectWithStream
      - azure-cognitiveservices-face.Face.detectWithStream_2
      - azure-cognitiveservices-face.Face.detectWithStream_1
      - >-
        azure-cognitiveservices-face.Face.detectWithStreamWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.detectWithUrl
      - azure-cognitiveservices-face.Face.detectWithUrl_2
      - azure-cognitiveservices-face.Face.detectWithUrl_1
      - azure-cognitiveservices-face.Face.detectWithUrlWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.findSimilar
      - azure-cognitiveservices-face.Face.findSimilar_2
      - azure-cognitiveservices-face.Face.findSimilar_1
      - azure-cognitiveservices-face.Face.findSimilarWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.group
      - azure-cognitiveservices-face.Face.group_2
      - azure-cognitiveservices-face.Face.group_1
      - azure-cognitiveservices-face.Face.groupWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.identify
      - azure-cognitiveservices-face.Face.identify_2
      - azure-cognitiveservices-face.Face.identify_1
      - azure-cognitiveservices-face.Face.identifyWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.verifyFaceToFace
      - azure-cognitiveservices-face.Face.verifyFaceToFace_2
      - azure-cognitiveservices-face.Face.verifyFaceToFace_1
      - >-
        azure-cognitiveservices-face.Face.verifyFaceToFaceWithHttpOperationResponse
      - azure-cognitiveservices-face.Face.verifyFaceToPerson
      - azure-cognitiveservices-face.Face.verifyFaceToPerson_2
      - azure-cognitiveservices-face.Face.verifyFaceToPerson_1
      - >-
        azure-cognitiveservices-face.Face.verifyFaceToPersonWithHttpOperationResponse
    langs:
      - typeScript
    type: interface
    summary: ''
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithStream
    name: 'detectWithStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Detect human faces in an image and returns face locations, and optionally
      with faceIds, landmarks, and attributes.
    syntax:
      content: 'function detectWithStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithStream_2
    name: 'detectWithStream(stream.Readable, Object, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Detect human faces in an image and returns face locations, and optionally
      with faceIds, landmarks, and attributes.
    syntax:
      content: >-
        function detectWithStream(image: stream.Readable, options: Object,
        callback: ServiceCallback<DetectedFace[]>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.DetectedFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithStream_1
    name: 'detectWithStream(stream.Readable, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Detect human faces in an image and returns face locations, and optionally
      with faceIds, landmarks, and attributes.
    syntax:
      content: >-
        function detectWithStream(image: stream.Readable, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.DetectedFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: >-
      azure-cognitiveservices-face.Face.detectWithStreamWithHttpOperationResponse
    name: 'detectWithStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Detect human faces in an image and returns face locations, and optionally
      with faceIds, landmarks, and attributes.
    syntax:
      content: >-
        function detectWithStreamWithHttpOperationResponse(image:
        stream.Readable, options?: Object)
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            An image stream.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.DetectedFace[]>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithUrl
    name: 'detectWithUrl(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with

      faceIds, landmarks, and attributes.<br />

      * Optional parameters including faceId, landmarks, and attributes.

      Attributes include age, gender, headPose, smile, facialHair, glasses,

      emotion, hair, makeup, occlusion, accessories, blur, exposure and noise.

      * The extracted face feature, instead of the actual image, will be stored
      on

      server. The faceId is an identifier of the face feature and will be used
      in

      [Face -

      Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),

      [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),

      and [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).

      It will expire 24 hours after the detection call.

      * Higher face image quality means better detection and recognition

      precision. Please consider high-quality faces: frontal, clear, and face
      size

      is 200x200 pixels (100 pixels between eyes) or bigger.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

      allowed image file size is from 1KB to 6MB.

      * Faces are detectable when its size is 36x36 to 4096x4096 pixels. If need

      to detect very small but clear faces, please try to enlarge the input
      image.

      * Up to 64 faces can be returned for an image. Faces are ranked by face

      rectangle size from large to small.

      * Face detector prefer frontal and near-frontal faces. There are cases
      that

      faces may not be detected, e.g. exceptionally large face angles
      (head-pose)

      or being occluded, or wrong image orientation.

      * Attributes (age, gender, headPose, smile, facialHair, glasses, emotion,

      hair, makeup, occlusion, accessories, blur, exposure and noise) may not be

      perfectly accurate. HeadPose's pitch value is a reserved field and will

      always return 0.

      * Different 'recognitionModel' values are provided. If follow-up
      operations

      like Verify, Identify, Find Similar are needed, please specify the

      recognition model with 'recognitionModel' parameter. The default value for

      'recognitionModel' is 'recognition_01', if latest model needed, please

      explicitly specify the model you need in this parameter. Once specified,
      the

      detected faceIds will be associated with the specified recognition model.

      More details, please refer to [How to specify a recognition

      model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    syntax:
      content: 'function detectWithUrl(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithUrl_2
    name: 'detectWithUrl(string, Object, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with

      faceIds, landmarks, and attributes.<br />

      * Optional parameters including faceId, landmarks, and attributes.

      Attributes include age, gender, headPose, smile, facialHair, glasses,

      emotion, hair, makeup, occlusion, accessories, blur, exposure and noise.

      * The extracted face feature, instead of the actual image, will be stored
      on

      server. The faceId is an identifier of the face feature and will be used
      in

      [Face -

      Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),

      [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),

      and [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).

      It will expire 24 hours after the detection call.

      * Higher face image quality means better detection and recognition

      precision. Please consider high-quality faces: frontal, clear, and face
      size

      is 200x200 pixels (100 pixels between eyes) or bigger.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

      allowed image file size is from 1KB to 6MB.

      * Faces are detectable when its size is 36x36 to 4096x4096 pixels. If need

      to detect very small but clear faces, please try to enlarge the input
      image.

      * Up to 64 faces can be returned for an image. Faces are ranked by face

      rectangle size from large to small.

      * Face detector prefer frontal and near-frontal faces. There are cases
      that

      faces may not be detected, e.g. exceptionally large face angles
      (head-pose)

      or being occluded, or wrong image orientation.

      * Attributes (age, gender, headPose, smile, facialHair, glasses, emotion,

      hair, makeup, occlusion, accessories, blur, exposure and noise) may not be

      perfectly accurate. HeadPose's pitch value is a reserved field and will

      always return 0.

      * Different 'recognitionModel' values are provided. If follow-up
      operations

      like Verify, Identify, Find Similar are needed, please specify the

      recognition model with 'recognitionModel' parameter. The default value for

      'recognitionModel' is 'recognition_01', if latest model needed, please

      explicitly specify the model you need in this parameter. Once specified,
      the

      detected faceIds will be associated with the specified recognition model.

      More details, please refer to [How to specify a recognition

      model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    syntax:
      content: >-
        function detectWithUrl(url: string, options: Object, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.DetectedFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithUrl_1
    name: 'detectWithUrl(string, ServiceCallback<DetectedFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with

      faceIds, landmarks, and attributes.<br />

      * Optional parameters including faceId, landmarks, and attributes.

      Attributes include age, gender, headPose, smile, facialHair, glasses,

      emotion, hair, makeup, occlusion, accessories, blur, exposure and noise.

      * The extracted face feature, instead of the actual image, will be stored
      on

      server. The faceId is an identifier of the face feature and will be used
      in

      [Face -

      Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),

      [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),

      and [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).

      It will expire 24 hours after the detection call.

      * Higher face image quality means better detection and recognition

      precision. Please consider high-quality faces: frontal, clear, and face
      size

      is 200x200 pixels (100 pixels between eyes) or bigger.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

      allowed image file size is from 1KB to 6MB.

      * Faces are detectable when its size is 36x36 to 4096x4096 pixels. If need

      to detect very small but clear faces, please try to enlarge the input
      image.

      * Up to 64 faces can be returned for an image. Faces are ranked by face

      rectangle size from large to small.

      * Face detector prefer frontal and near-frontal faces. There are cases
      that

      faces may not be detected, e.g. exceptionally large face angles
      (head-pose)

      or being occluded, or wrong image orientation.

      * Attributes (age, gender, headPose, smile, facialHair, glasses, emotion,

      hair, makeup, occlusion, accessories, blur, exposure and noise) may not be

      perfectly accurate. HeadPose's pitch value is a reserved field and will

      always return 0.

      * Different 'recognitionModel' values are provided. If follow-up
      operations

      like Verify, Identify, Find Similar are needed, please specify the

      recognition model with 'recognitionModel' parameter. The default value for

      'recognitionModel' is 'recognition_01', if latest model needed, please

      explicitly specify the model you need in this parameter. Once specified,
      the

      detected faceIds will be associated with the specified recognition model.

      More details, please refer to [How to specify a recognition

      model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    syntax:
      content: >-
        function detectWithUrl(url: string, callback:
        ServiceCallback<DetectedFace[]>)
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.DetectedFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.detectWithUrlWithHttpOperationResponse
    name: 'detectWithUrlWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Detect human faces in an image, return face rectangles, and optionally
      with

      faceIds, landmarks, and attributes.<br />

      * Optional parameters including faceId, landmarks, and attributes.

      Attributes include age, gender, headPose, smile, facialHair, glasses,

      emotion, hair, makeup, occlusion, accessories, blur, exposure and noise.

      * The extracted face feature, instead of the actual image, will be stored
      on

      server. The faceId is an identifier of the face feature and will be used
      in

      [Face -

      Identify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395239),

      [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a),

      and [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237).

      It will expire 24 hours after the detection call.

      * Higher face image quality means better detection and recognition

      precision. Please consider high-quality faces: frontal, clear, and face
      size

      is 200x200 pixels (100 pixels between eyes) or bigger.

      * JPEG, PNG, GIF (the first frame), and BMP format are supported. The

      allowed image file size is from 1KB to 6MB.

      * Faces are detectable when its size is 36x36 to 4096x4096 pixels. If need

      to detect very small but clear faces, please try to enlarge the input
      image.

      * Up to 64 faces can be returned for an image. Faces are ranked by face

      rectangle size from large to small.

      * Face detector prefer frontal and near-frontal faces. There are cases
      that

      faces may not be detected, e.g. exceptionally large face angles
      (head-pose)

      or being occluded, or wrong image orientation.

      * Attributes (age, gender, headPose, smile, facialHair, glasses, emotion,

      hair, makeup, occlusion, accessories, blur, exposure and noise) may not be

      perfectly accurate. HeadPose's pitch value is a reserved field and will

      always return 0.

      * Different 'recognitionModel' values are provided. If follow-up
      operations

      like Verify, Identify, Find Similar are needed, please specify the

      recognition model with 'recognitionModel' parameter. The default value for

      'recognitionModel' is 'recognition_01', if latest model needed, please

      explicitly specify the model you need in this parameter. Once specified,
      the

      detected faceIds will be associated with the specified recognition model.

      More details, please refer to [How to specify a recognition

      model](https://docs.microsoft.com/en-us/azure/cognitive-services/face/face-api-how-to-topics/specify-recognition-model)
    syntax:
      content: >-
        function detectWithUrlWithHttpOperationResponse(url: string, options?:
        Object)
      parameters:
        - id: url
          type:
            - string
          description: |
            Publicly reachable URL of an image
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.DetectedFace[]>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.findSimilar
    name: 'findSimilar(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Given query face's faceId, to search the similar-looking faces from a
      faceId

      array, a face list or a large face list. faceId array contains the faces

      created by [Face -

      Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),

      which will expire 24 hours after creation. A "faceListId" is created by

      [FaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)

      containing persistedFaceIds that will not expire. And a "largeFaceListId"
      is

      created by [LargeFaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)

      containing persistedFaceIds that will also not expire. Depending on the

      input the returned similar faces list contains faceIds or persistedFaceIds

      ranked by similarity.

      <br/>Find similar has two working modes, "matchPerson" and "matchFace".

      "matchPerson" is the default mode that it tries to find faces of the same

      person as possible by using internal same-person thresholds. It is useful
      to

      find a known person's other photos. Note that an empty list will be
      returned

      if no faces pass the internal thresholds. "matchFace" mode ignores

      same-person thresholds and returns ranked similar faces anyway, even the

      similarity is low. It can be used in the cases like searching

      celebrity-looking faces.

      <br/>The 'recognitionModel' associated with the query face's faceId should

      be the same as the 'recognitionModel' used by the target faceId array,
      face

      list or large face list.
    syntax:
      content: 'function findSimilar(faceId: string, options?: Object)'
      parameters:
        - id: faceId
          type:
            - string
          description: >
            FaceId of the query face. User needs to call Face -

            Detect first to get a valid faceId. Note that this faceId is not
            persisted

            and will expire 24 hours after the detection call
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.SimilarFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.findSimilar_2
    name: 'findSimilar(string, Object, ServiceCallback<SimilarFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Given query face's faceId, to search the similar-looking faces from a
      faceId

      array, a face list or a large face list. faceId array contains the faces

      created by [Face -

      Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),

      which will expire 24 hours after creation. A "faceListId" is created by

      [FaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)

      containing persistedFaceIds that will not expire. And a "largeFaceListId"
      is

      created by [LargeFaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)

      containing persistedFaceIds that will also not expire. Depending on the

      input the returned similar faces list contains faceIds or persistedFaceIds

      ranked by similarity.

      <br/>Find similar has two working modes, "matchPerson" and "matchFace".

      "matchPerson" is the default mode that it tries to find faces of the same

      person as possible by using internal same-person thresholds. It is useful
      to

      find a known person's other photos. Note that an empty list will be
      returned

      if no faces pass the internal thresholds. "matchFace" mode ignores

      same-person thresholds and returns ranked similar faces anyway, even the

      similarity is low. It can be used in the cases like searching

      celebrity-looking faces.

      <br/>The 'recognitionModel' associated with the query face's faceId should

      be the same as the 'recognitionModel' used by the target faceId array,
      face

      list or large face list.
    syntax:
      content: >-
        function findSimilar(faceId: string, options: Object, callback:
        ServiceCallback<SimilarFace[]>)
      parameters:
        - id: faceId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.SimilarFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.SimilarFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.findSimilar_1
    name: 'findSimilar(string, ServiceCallback<SimilarFace[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Given query face's faceId, to search the similar-looking faces from a
      faceId

      array, a face list or a large face list. faceId array contains the faces

      created by [Face -

      Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),

      which will expire 24 hours after creation. A "faceListId" is created by

      [FaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)

      containing persistedFaceIds that will not expire. And a "largeFaceListId"
      is

      created by [LargeFaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)

      containing persistedFaceIds that will also not expire. Depending on the

      input the returned similar faces list contains faceIds or persistedFaceIds

      ranked by similarity.

      <br/>Find similar has two working modes, "matchPerson" and "matchFace".

      "matchPerson" is the default mode that it tries to find faces of the same

      person as possible by using internal same-person thresholds. It is useful
      to

      find a known person's other photos. Note that an empty list will be
      returned

      if no faces pass the internal thresholds. "matchFace" mode ignores

      same-person thresholds and returns ranked similar faces anyway, even the

      similarity is low. It can be used in the cases like searching

      celebrity-looking faces.

      <br/>The 'recognitionModel' associated with the query face's faceId should

      be the same as the 'recognitionModel' used by the target faceId array,
      face

      list or large face list.
    syntax:
      content: >-
        function findSimilar(faceId: string, callback:
        ServiceCallback<SimilarFace[]>)
      parameters:
        - id: faceId
          type:
            - string
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.SimilarFace[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.SimilarFace[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.findSimilarWithHttpOperationResponse
    name: 'findSimilarWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Given query face's faceId, to search the similar-looking faces from a
      faceId

      array, a face list or a large face list. faceId array contains the faces

      created by [Face -

      Detect](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395236),

      which will expire 24 hours after creation. A "faceListId" is created by

      [FaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039524b)

      containing persistedFaceIds that will not expire. And a "largeFaceListId"
      is

      created by [LargeFaceList -

      Create](/docs/services/563879b61984550e40cbbe8d/operations/5a157b68d2de3616c086f2cc)

      containing persistedFaceIds that will also not expire. Depending on the

      input the returned similar faces list contains faceIds or persistedFaceIds

      ranked by similarity.

      <br/>Find similar has two working modes, "matchPerson" and "matchFace".

      "matchPerson" is the default mode that it tries to find faces of the same

      person as possible by using internal same-person thresholds. It is useful
      to

      find a known person's other photos. Note that an empty list will be
      returned

      if no faces pass the internal thresholds. "matchFace" mode ignores

      same-person thresholds and returns ranked similar faces anyway, even the

      similarity is low. It can be used in the cases like searching

      celebrity-looking faces.

      <br/>The 'recognitionModel' associated with the query face's faceId should

      be the same as the 'recognitionModel' used by the target faceId array,
      face

      list or large face list.
    syntax:
      content: >-
        function findSimilarWithHttpOperationResponse(faceId: string, options?:
        Object)
      parameters:
        - id: faceId
          type:
            - string
          description: >
            FaceId of the query face. User needs to call Face -

            Detect first to get a valid faceId. Note that this faceId is not
            persisted

            and will expire 24 hours after the detection call
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.SimilarFace[]>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.group
    name: 'group(string[], Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Divide candidate faces into groups based on face similarity.<br />

      * The output is one or more disjointed face groups and a messyGroup. A
      face

      group contains faces that have similar looking, often of the same person.

      Face groups are ranked by group size, i.e. number of faces. Notice that

      faces belonging to a same person might be split into several groups in the

      result.

      * MessyGroup is a special face group containing faces that cannot find any

      similar counterpart face from original faces. The messyGroup will not
      appear

      in the result if all faces found their counterparts.

      * Group API needs at least 2 candidate faces and 1000 at most. We suggest
      to

      try [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)

      when you only have 2 candidate faces.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same.
    syntax:
      content: 'function group(faceIds: string[], options?: Object)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: |
            Array of candidate faceId created by Face - Detect.
            The maximum is 1000 faces
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-face.GroupResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.group_2
    name: 'group(string[], Object, ServiceCallback<GroupResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Divide candidate faces into groups based on face similarity.<br />

      * The output is one or more disjointed face groups and a messyGroup. A
      face

      group contains faces that have similar looking, often of the same person.

      Face groups are ranked by group size, i.e. number of faces. Notice that

      faces belonging to a same person might be split into several groups in the

      result.

      * MessyGroup is a special face group containing faces that cannot find any

      similar counterpart face from original faces. The messyGroup will not
      appear

      in the result if all faces found their counterparts.

      * Group API needs at least 2 candidate faces and 1000 at most. We suggest
      to

      try [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)

      when you only have 2 candidate faces.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same.
    syntax:
      content: >-
        function group(faceIds: string[], options: Object, callback:
        ServiceCallback<GroupResult>)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.GroupResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.GroupResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.group_1
    name: 'group(string[], ServiceCallback<GroupResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Divide candidate faces into groups based on face similarity.<br />

      * The output is one or more disjointed face groups and a messyGroup. A
      face

      group contains faces that have similar looking, often of the same person.

      Face groups are ranked by group size, i.e. number of faces. Notice that

      faces belonging to a same person might be split into several groups in the

      result.

      * MessyGroup is a special face group containing faces that cannot find any

      similar counterpart face from original faces. The messyGroup will not
      appear

      in the result if all faces found their counterparts.

      * Group API needs at least 2 candidate faces and 1000 at most. We suggest
      to

      try [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)

      when you only have 2 candidate faces.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same.
    syntax:
      content: >-
        function group(faceIds: string[], callback:
        ServiceCallback<GroupResult>)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.GroupResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.GroupResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.groupWithHttpOperationResponse
    name: 'groupWithHttpOperationResponse(string[], Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Divide candidate faces into groups based on face similarity.<br />

      * The output is one or more disjointed face groups and a messyGroup. A
      face

      group contains faces that have similar looking, often of the same person.

      Face groups are ranked by group size, i.e. number of faces. Notice that

      faces belonging to a same person might be split into several groups in the

      result.

      * MessyGroup is a special face group containing faces that cannot find any

      similar counterpart face from original faces. The messyGroup will not
      appear

      in the result if all faces found their counterparts.

      * Group API needs at least 2 candidate faces and 1000 at most. We suggest
      to

      try [Face -

      Verify](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f3039523a)

      when you only have 2 candidate faces.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same.
    syntax:
      content: >-
        function groupWithHttpOperationResponse(faceIds: string[], options?:
        Object)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: |
            Array of candidate faceId created by Face - Detect.
            The maximum is 1000 faces
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.GroupResult>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.identify
    name: 'identify(string[], Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >+
      1-to-many identification to find the closest matches of the specific query

      person face from a person group or large person group.

      <br/> For each face in the faceIds array, Face Identify will compute

      similarities between the query face and all the faces in the person group

      (given by personGroupId) or large person group (given by

      largePersonGroupId), and return candidate person(s) for that face ranked
      by

      similarity confidence. The person group/large person group should be
      trained

      to make it ready for identification. See more in [PersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)

      and [LargePersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).

      <br/>

      Remarks:<br />

      * The algorithm allows more than one face to be identified independently
      at

      the same request, but no more than 10 faces.

      * Each person in the person group/large person group could have more than

      one face, but no more than 248 faces.

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * Number of candidates returned is restricted by
      maxNumOfCandidatesReturned

      and confidenceThreshold. If no person is identified, the returned
      candidates

      will be an empty array.

      * Try [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)

      when you need to find similar faces from a face list/large face list
      instead

      of a person group/large person group.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target person group or
      large

      person group.

    syntax:
      content: 'function identify(faceIds: string[], options?: Object)'
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: >
            Array of query faces faceIds, created by the Face -

            Detect. Each of the faces are identified independently. The valid
            number of

            faceIds is between [1, 10].
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.IdentifyResult[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.identify_2
    name: 'identify(string[], Object, ServiceCallback<IdentifyResult[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >+
      1-to-many identification to find the closest matches of the specific query

      person face from a person group or large person group.

      <br/> For each face in the faceIds array, Face Identify will compute

      similarities between the query face and all the faces in the person group

      (given by personGroupId) or large person group (given by

      largePersonGroupId), and return candidate person(s) for that face ranked
      by

      similarity confidence. The person group/large person group should be
      trained

      to make it ready for identification. See more in [PersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)

      and [LargePersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).

      <br/>

      Remarks:<br />

      * The algorithm allows more than one face to be identified independently
      at

      the same request, but no more than 10 faces.

      * Each person in the person group/large person group could have more than

      one face, but no more than 248 faces.

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * Number of candidates returned is restricted by
      maxNumOfCandidatesReturned

      and confidenceThreshold. If no person is identified, the returned
      candidates

      will be an empty array.

      * Try [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)

      when you need to find similar faces from a face list/large face list
      instead

      of a person group/large person group.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target person group or
      large

      person group.

    syntax:
      content: >-
        function identify(faceIds: string[], options: Object, callback:
        ServiceCallback<IdentifyResult[]>)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.IdentifyResult[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.IdentifyResult[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.identify_1
    name: 'identify(string[], ServiceCallback<IdentifyResult[]>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >+
      1-to-many identification to find the closest matches of the specific query

      person face from a person group or large person group.

      <br/> For each face in the faceIds array, Face Identify will compute

      similarities between the query face and all the faces in the person group

      (given by personGroupId) or large person group (given by

      largePersonGroupId), and return candidate person(s) for that face ranked
      by

      similarity confidence. The person group/large person group should be
      trained

      to make it ready for identification. See more in [PersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)

      and [LargePersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).

      <br/>

      Remarks:<br />

      * The algorithm allows more than one face to be identified independently
      at

      the same request, but no more than 10 faces.

      * Each person in the person group/large person group could have more than

      one face, but no more than 248 faces.

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * Number of candidates returned is restricted by
      maxNumOfCandidatesReturned

      and confidenceThreshold. If no person is identified, the returned
      candidates

      will be an empty array.

      * Try [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)

      when you need to find similar faces from a face list/large face list
      instead

      of a person group/large person group.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target person group or
      large

      person group.

    syntax:
      content: >-
        function identify(faceIds: string[], callback:
        ServiceCallback<IdentifyResult[]>)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: ''
        - id: callback
          type:
            - 'ServiceCallback<azure-cognitiveservices-face.IdentifyResult[]>'
          description: ''
      return:
        type:
          - 'Promise<azure-cognitiveservices-face.IdentifyResult[]>'
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.identifyWithHttpOperationResponse
    name: 'identifyWithHttpOperationResponse(string[], Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >+
      1-to-many identification to find the closest matches of the specific query

      person face from a person group or large person group.

      <br/> For each face in the faceIds array, Face Identify will compute

      similarities between the query face and all the faces in the person group

      (given by personGroupId) or large person group (given by

      largePersonGroupId), and return candidate person(s) for that face ranked
      by

      similarity confidence. The person group/large person group should be
      trained

      to make it ready for identification. See more in [PersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395249)

      and [LargePersonGroup -

      Train](/docs/services/563879b61984550e40cbbe8d/operations/599ae2d16ac60f11b48b5aa4).

      <br/>

      Remarks:<br />

      * The algorithm allows more than one face to be identified independently
      at

      the same request, but no more than 10 faces.

      * Each person in the person group/large person group could have more than

      one face, but no more than 248 faces.

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * Number of candidates returned is restricted by
      maxNumOfCandidatesReturned

      and confidenceThreshold. If no person is identified, the returned
      candidates

      will be an empty array.

      * Try [Face - Find

      Similar](/docs/services/563879b61984550e40cbbe8d/operations/563879b61984550f30395237)

      when you need to find similar faces from a face list/large face list
      instead

      of a person group/large person group.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target person group or
      large

      person group.

    syntax:
      content: >-
        function identifyWithHttpOperationResponse(faceIds: string[], options?:
        Object)
      parameters:
        - id: faceIds
          type:
            - 'string[]'
          description: >
            Array of query faces faceIds, created by the Face -

            Detect. Each of the faces are identified independently. The valid
            number of

            faceIds is between [1, 10].
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.IdentifyResult[]>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToFace
    name: 'verifyFaceToFace(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person or whether one face
      belongs

      to a person.

      <br/>

      Remarks:<br />

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * For the scenarios that are sensitive to accuracy please make your own

      judgment.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target face, person group
      or

      large person group.
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, options?:
        Object)
      parameters:
        - id: faceId1
          type:
            - string
          description: |
            FaceId of the first face, comes from Face - Detect
        - id: faceId2
          type:
            - string
          description: |
            FaceId of the second face, comes from Face - Detect
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToFace_2
    name: 'verifyFaceToFace(string, string, Object, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person or whether one face
      belongs

      to a person.

      <br/>

      Remarks:<br />

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * For the scenarios that are sensitive to accuracy please make your own

      judgment.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target face, person group
      or

      large person group.
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, options:
        Object, callback: ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId1
          type:
            - string
          description: ''
        - id: faceId2
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.VerifyResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToFace_1
    name: 'verifyFaceToFace(string, string, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person or whether one face
      belongs

      to a person.

      <br/>

      Remarks:<br />

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * For the scenarios that are sensitive to accuracy please make your own

      judgment.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target face, person group
      or

      large person group.
    syntax:
      content: >-
        function verifyFaceToFace(faceId1: string, faceId2: string, callback:
        ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId1
          type:
            - string
          description: ''
        - id: faceId2
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.VerifyResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: >-
      azure-cognitiveservices-face.Face.verifyFaceToFaceWithHttpOperationResponse
    name: 'verifyFaceToFaceWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person or whether one face
      belongs

      to a person.

      <br/>

      Remarks:<br />

      * Higher face image quality means better identification precision. Please

      consider high-quality faces: frontal, clear, and face size is 200x200
      pixels

      (100 pixels between eyes) or bigger.

      * For the scenarios that are sensitive to accuracy please make your own

      judgment.

      * The 'recognitionModel' associated with the query faces' faceIds should
      be

      the same as the 'recognitionModel' used by the target face, person group
      or

      large person group.
    syntax:
      content: >-
        function verifyFaceToFaceWithHttpOperationResponse(faceId1: string,
        faceId2: string, options?: Object)
      parameters:
        - id: faceId1
          type:
            - string
          description: |
            FaceId of the first face, comes from Face - Detect
        - id: faceId2
          type:
            - string
          description: |
            FaceId of the second face, comes from Face - Detect
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.VerifyResult>>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToPerson
    name: 'verifyFaceToPerson(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person. Compares a face Id with
      a

      Person Id
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, options?:
        Object)
      parameters:
        - id: faceId
          type:
            - string
          description: |
            FaceId of the face, comes from Face - Detect
        - id: personId
          type:
            - string
          description: |
            Specify a certain person in a person group or a large
            person group. personId is created in PersonGroup Person - Create or
            LargePersonGroup Person - Create.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToPerson_2
    name: 'verifyFaceToPerson(string, string, Object, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person. Compares a face Id with
      a

      Person Id
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, options:
        Object, callback: ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId
          type:
            - string
          description: ''
        - id: personId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.VerifyResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: azure-cognitiveservices-face.Face.verifyFaceToPerson_1
    name: 'verifyFaceToPerson(string, string, ServiceCallback<VerifyResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person. Compares a face Id with
      a

      Person Id
    syntax:
      content: >-
        function verifyFaceToPerson(faceId: string, personId: string, callback:
        ServiceCallback<VerifyResult>)
      parameters:
        - id: faceId
          type:
            - string
          description: ''
        - id: personId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-face.VerifyResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-face.VerifyResult>
    package: azure-cognitiveservices-face
  - uid: >-
      azure-cognitiveservices-face.Face.verifyFaceToPersonWithHttpOperationResponse
    name: 'verifyFaceToPersonWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: >-
      Verify whether two faces belong to a same person. Compares a face Id with
      a

      Person Id
    syntax:
      content: >-
        function verifyFaceToPersonWithHttpOperationResponse(faceId: string,
        personId: string, options?: Object)
      parameters:
        - id: faceId
          type:
            - string
          description: |
            FaceId of the face, comes from Face - Detect
        - id: personId
          type:
            - string
          description: |
            Specify a certain person in a person group or a large
            person group. personId is created in PersonGroup Person - Create or
            LargePersonGroup Person - Create.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - >-
            Promise<HttpOperationResponse<azure-cognitiveservices-face.VerifyResult>>
    package: azure-cognitiveservices-face
references:
  - uid: 'Promise<azure-cognitiveservices-face.DetectedFace[]>'
    name: 'DetectedFace[]>'
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DetectedFace
        fullName: DetectedFace
        uid: azure-cognitiveservices-face.DetectedFace
      - name: '[]>'
        fullName: '[]>'
  - uid: 'ServiceCallback<azure-cognitiveservices-face.DetectedFace[]>'
    name: 'DetectedFace[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectedFace
        fullName: DetectedFace
        uid: azure-cognitiveservices-face.DetectedFace
      - name: '[]>'
        fullName: '[]>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-face.DetectedFace[]>>
    name: 'DetectedFace[]>>'
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DetectedFace
        fullName: DetectedFace
        uid: azure-cognitiveservices-face.DetectedFace
      - name: '[]>>'
        fullName: '[]>>'
  - uid: 'Promise<azure-cognitiveservices-face.SimilarFace[]>'
    name: 'SimilarFace[]>'
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: SimilarFace
        fullName: SimilarFace
        uid: azure-cognitiveservices-face.SimilarFace
      - name: '[]>'
        fullName: '[]>'
  - uid: 'ServiceCallback<azure-cognitiveservices-face.SimilarFace[]>'
    name: 'SimilarFace[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: SimilarFace
        fullName: SimilarFace
        uid: azure-cognitiveservices-face.SimilarFace
      - name: '[]>'
        fullName: '[]>'
  - uid: 'Promise<HttpOperationResponse<azure-cognitiveservices-face.SimilarFace[]>>'
    name: 'SimilarFace[]>>'
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: SimilarFace
        fullName: SimilarFace
        uid: azure-cognitiveservices-face.SimilarFace
      - name: '[]>>'
        fullName: '[]>>'
  - uid: Promise<azure-cognitiveservices-face.GroupResult>
    name: GroupResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: GroupResult
        fullName: GroupResult
        uid: azure-cognitiveservices-face.GroupResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-face.GroupResult>
    name: GroupResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: GroupResult
        fullName: GroupResult
        uid: azure-cognitiveservices-face.GroupResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-face.GroupResult>>
    name: GroupResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: GroupResult
        fullName: GroupResult
        uid: azure-cognitiveservices-face.GroupResult
      - name: '>>'
        fullName: '>>'
  - uid: 'Promise<azure-cognitiveservices-face.IdentifyResult[]>'
    name: 'IdentifyResult[]>'
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: IdentifyResult
        fullName: IdentifyResult
        uid: azure-cognitiveservices-face.IdentifyResult
      - name: '[]>'
        fullName: '[]>'
  - uid: 'ServiceCallback<azure-cognitiveservices-face.IdentifyResult[]>'
    name: 'IdentifyResult[]>'
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: IdentifyResult
        fullName: IdentifyResult
        uid: azure-cognitiveservices-face.IdentifyResult
      - name: '[]>'
        fullName: '[]>'
  - uid: >-
      Promise<HttpOperationResponse<azure-cognitiveservices-face.IdentifyResult[]>>
    name: 'IdentifyResult[]>>'
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: IdentifyResult
        fullName: IdentifyResult
        uid: azure-cognitiveservices-face.IdentifyResult
      - name: '[]>>'
        fullName: '[]>>'
  - uid: Promise<azure-cognitiveservices-face.VerifyResult>
    name: VerifyResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: VerifyResult
        fullName: VerifyResult
        uid: azure-cognitiveservices-face.VerifyResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-face.VerifyResult>
    name: VerifyResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: VerifyResult
        fullName: VerifyResult
        uid: azure-cognitiveservices-face.VerifyResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-face.VerifyResult>>
    name: VerifyResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: VerifyResult
        fullName: VerifyResult
        uid: azure-cognitiveservices-face.VerifyResult
      - name: '>>'
        fullName: '>>'
